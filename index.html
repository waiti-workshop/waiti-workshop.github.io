<!DOCTYPE html>
<html lang='en'>

<head>
    <base href=".">
    <link rel="shortcut icon" type="image/png" href="assets/logo2.png"/>
    <link rel="stylesheet" type="text/css" media="all" href="assets/main.css"/>
    <meta name="description" content="Conference Template">
    <meta name="resource-type" content="document">
    <meta name="distribution" content="global">
    <meta name="KeyWords" content="Conference">
    <title>WAITI</title>
</head>

<body>

    <div class="banner">
        <img src="assets/location-crop.jpg" alt="Conference Template Banner">
        <div class="top-left">
            <span class="title1">Workshop on AI for Cyber Threat Intelligence </span><span class="title2">(WAITI) </span> <span class="year">2025</span>
        </div>
        <div class="bottom-right">
            December 8, 2025, Hawaii, USA <br> co-located with the Annual Computer Security Applications Conference (ACSAC25)
        </div>
    </div>

    <table class="navigation">
        <tr>
            <td class="navigation"> 
                <a class="current" title="Call for Papers" href="./index.html">Call for Papers</a>
            </td>
            <td class="navigation">
                <a title="Important Dates" href="dates/index.html">Important Dates</a>
            </td>
            <td class="navigation">
                <a title="Organizing Committee" href="committee/index.html">Committee</a>
            </td>
            <td class="navigation">
                <a title="Register for the Conference" href="registration/index.html">Attend</a>
            </td>
             <td class="navigation">
                <a title="Past Events" href="previous/index.html">Past Events</a>
            </td>
        </tr>
    </table>

    <p>
        The second Workshop on AI for Cyber Threat Intelligence (WAITI 2025) will be held on
        Monday, December 8, 2025, in conjunction with the Annual Computer Security Applications
        Conference - ACSAC (https://www.acsac.org/). ACSAC will be held in Hawaii, USA. We have
        merged the IoT Security and Cyber Threat Intelligence (IoT-SCTI) Workshop with WAITI to
        cater to a wider audience.  
    </p>

    <h2>Call for Papers</h2>
    <p>
        The cybersecurity landscape is in constant flux, inundating security professionals with an
        overwhelming and ever-growing data stream. Hidden within this torrent are critical insights
        ranging from textual indicators on social media and technical reports to discussions on dark
        web forums that, if properly harnessed, can offer a strategic edge. Cyber Threat Intelligence
        (CTI) has traditionally relied heavily on manual analysis or rudimentary keyword-based
        methods, resulting in significant inefficiencies, delayed responses, and missed threat signals.
        Today, security analysts are challenged not only by the sheer volume of data but also by
        increasingly sophisticated adversarial techniques such as code obfuscation, misinformation
        campaigns, and advanced social engineering. The rapid pace of threat evolution demands not
        just faster but smarter ways to extract intelligence and respond effectively. This is where
        Natural Language Processing (NLP), and in particular, Large Language Models (LLMs), are
        proving revolutionary. LLMs represent a paradigm shift in how we process and understand
        unstructured text data. With their unparalleled ability to comprehend context, generate
        insights, and reason over language, LLMs have become indispensable in the CTI pipeline.
        They enable scalable automation, accurate threat interpretation, and real-time intelligence
        extraction from diverse and complex textual sources. By leveraging the deep understanding
        and generative capabilities of LLMs, organizations can go beyond reactive defense
        mechanisms to develop proactive, anticipatory strategies that adapt to emerging threats with
        unprecedented speed and precision.

        This workshop aims to spotlight the transformative potential of Artificial Intelligence, NLP,
        and especially LLMs in revolutionizing cybersecurity focusing on their application in CTI
        gathering and analysis. It will provide a vibrant platform for researchers, practitioners, and
        enthusiasts to explore cutting-edge approaches, share breakthroughs, and foster
        collaboration in shaping the future of intelligent cyber defense.

    </p>
    <p>
        We encourage original and high-quality contributions, preliminary work, and novel ideas on topics, including but not limited to:

        <ul>
            <li>Information extraction in cyber threat intelligence</li>
            <li>Deep learning architectures for threat detection and analysis</li>
            <li>Visualization techniques for CTI</li>
            <li>Large Language Models for CTI</li>
            <li>Intelligence-driven threat-hunting</li>
            <li>Attribution</li>
            <li>Sharing of CTI</li>
            <li>Hunting and Tracking Adversaries</li>
            <li>Threat Quantification & Prioritization</li>
            <li>Explainable AI in Cybersecurity</li>
            <li>Dynamic Threat Adaptation with LLMs</li>
            <li>Multimodal Threat Intelligence Fusion</li>
            <li>LLMs for Malware Detection</li>
            <li>Bias Mitigation in LLMs for Cyber Threat Intelligence</li>
            <li>Federated Learning for Threat Detection</li>
            <li>LLMs for Social Media Threat Analysis</li>
            <li>LLMs and Visual Content</li>
            <li>Multimodal Large Language Models (MLLMs)</li>
            <li>Understanding Technical Language for CTI</li>
            <li>Cross-lingual Threat Intelligence using LLMs</li>
            <li>Misinformation Detection in CTI with LLMs</li>
            <li>LLM-powered Threat Scenario Generation</li>
            <li>Human-in-the-loop systems for LLM-based CTI</li>
            <li>Explainable Threat Intelligence Reports with LLMs</li>
            <li>Benchmarking LLM Performance</li>
            <li>Legal and Ethical Considerations for AI</li>
            <li>Zero Trust and CTI</li>
            <li>CTI in the IoT domain</li>
            <li>AI/GenAI for users’ behavior analysis and inference</li>
            <li>GenAI for mobility management and network control</li>
            <li>AI/GenAI within 6G networks</li>
            <li>Blockchain-based approaches for CTI</li>
            <li>Applying CTI/Case Studies</li>
            <li>CTI for IoT Systems</li>
            <li>Using IoT for sourcing CTI</li>
            <li>Network and host-based intrusion detection systems for IoT</li>
            <li>Web crawlers and scrapers for IoT threat information</li>
            <li>Cyber threat intelligence feeds focusing on IoT</li>
            <li>Static and dynamic malware analysis for IoT</li>
            <li>Machine learning and data mining techniques for IoT threat analysis</li>
            <li>IoT-specific threat actor profiling and attribution</li>
            <li>Domain generation algorithms analysis for IoT malware</li>
            <li>Identifying trends and patterns in IoT attacks and vulnerabilities</li>
            <li>Correlating IoT threat data from multiple sources</li>
            <li>Evaluating the reliability and accuracy of IoT CTI sources</li>
            <li>Addressing false positives and noise in IoT threat data</li>
            <li>Collaborative platforms for sharing and responding to IoT threats</li>
            <li>LLM-driven anomaly and fault detection in networks</li>
            <li>LLMs for Network Security and Privacy</li>
            <li>LLMs for detecting malware in network traffic</li>
            <li>QoS/QoE prediction and optimization using LLMs</li>
            <li>Federated learning with LLMs</li>
            <li>LLMs and Network Data Analytics</li>
            <li>Summarization of network incidents and logs via LLMs</li>
            <li>LLM Applications in 6G, IoT, and space-terrestrial integrated networks</li>
            <li>Ethical considerations, fairness, and bias in LLM-driven systems</li>
            <li>LLMs for cybersecurity education and training in networked environments</li>
        </ul>
        
        Submissions should consist of a PDF with no more than 6 double-column pages, excluding references and appendices (max 2 pages). The total PDF must not exceed 8 pages.
        <ul>
            <li>Paper Format: Use the IEEE template for your ACSAC paper, <a href="https://www.ieee.org/conferences/publishing/templates.html">https://www.ieee.org/conferences/publishing/templates.html</a>. For Latex, use \documentclass[conference,compsoc]{IEEEtran}.</li>
            <li>Anonymity: Submissions must be anonymous. Author names and affiliations should not be included. Authors can cite their work but must do so in the third person.</li>
            <li>Submission Website: <a href="https://cmt3.research.microsoft.com/WAITI2025/">https://cmt3.research.microsoft.com/WAITI2025/.</a> (The Microsoft CMT service was used for managing the peer-reviewing process for this conference. This service was provided for free by Microsoft, and they bore all expenses, including costs for Azure cloud services as well as for software development and support.).</li>
        </ul>
        
        We also encourage submitting Systemization-of-Knowledge (SoK) papers that distill the intersection of LLM and cybersecurity of previously published articles.

    </p>

    <h2>Publication</h2>
    <p>
        Accepted papers will be published by IEEE Computer Society Conference Publishing Services (CPS) and will appear in the Computer Society Digital Library and IEEE Xplore® in an ACSAC Workshops 2025 volume alongside the main ACSAC 2025 proceedings.
        An additional small publication fee will be required.
    </p>


    <footer>
        &copy; Conference Organizers
    </footer>

</body>
</html>

